{
  "description": "A large dataset is pulled to the driver before filtering, causing out-of-memory failures. Fix the pipeline to filter in Spark before any action.",
  "starterCode": "purchase_events = events_df.collect().filter(F.col(\"event_type\") == \"purchase\")",
  "expectedPattern": "events_df\\.filter\\s*\\(\\s*F\\.col\\(\\\"event_type\\\"\\)\\s*==\\s*\\\"purchase\\\"\\s*\\)",
  "simulatedOutput": "Issue: Driver OOM when processing billions of rows.",
  "hints": [
    "collect() is an action that brings all rows to the driver.",
    "Keep the logic as a DataFrame transformation.",
    "Filter on event_type inside Spark execution."
  ]
}
